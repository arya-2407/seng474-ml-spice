{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of collaborative filtering models\n",
    "We run the collaborative filtering model from amazon.ipynb and evaluate the results based on a root mean squared error between a predicted rating on a holdout data point and the actual rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import ops\n",
    "\n",
    "# Import utils from subfolder of project, works for immediate subfolders of PROJECT_ROOT\n",
    "PROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), \"..\")) # adjust relative import as necessary\n",
    "sys.path.append(PROJECT_ROOT)\n",
    "from utils.data_processing import get_filtered_review_data, get_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading preprocessed data from data/Video_Games_min5_test1_val1_cols['user_id', 'product_id', 'timestamp', 'title', 'text', 'helpful_vote'].pkl\n",
      "Loading metadata from data/Video_Games_metadata.pkl\n"
     ]
    }
   ],
   "source": [
    "CATEGORY = 'Video_Games'\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_filtered_review_data(CATEGORY)\n",
    "metadata = get_metadata(CATEGORY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RecommenderNet implementation copied from amazon.ipynb notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommenderNet(keras.Model):\n",
    "    def __init__(self, num_users, num_products, embedding_size, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.num_users = num_users\n",
    "        self.num_products = num_products\n",
    "        self.embedding_size = embedding_size\n",
    "        self.user_embedding = layers.Embedding(\n",
    "            num_users,\n",
    "            embedding_size,\n",
    "            embeddings_initializer=\"he_normal\",\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
    "        )\n",
    "        self.user_bias = layers.Embedding(num_users, 1)\n",
    "        self.product_embedding = layers.Embedding(\n",
    "            num_products,\n",
    "            embedding_size,\n",
    "            embeddings_initializer=\"he_normal\",\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
    "        )\n",
    "        self.product_bias = layers.Embedding(num_products, 1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        user_vector = self.user_embedding(inputs[:, 0])\n",
    "        user_bias = self.user_bias(inputs[:, 0])\n",
    "        product_vector = self.product_embedding(inputs[:, 1])\n",
    "        product_bias = self.product_bias(inputs[:, 1])\n",
    "\n",
    "        dot_user_product = ops.tensordot(user_vector, product_vector, 2)\n",
    "        a = dot_user_product + user_bias + product_bias\n",
    "        \n",
    "        return ops.nn.sigmoid(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to merge the product ids since there are some products that only appear on the validation or test datasets, not the training set\n",
    "num_users = len(pd.concat([X_train['user_id'], X_val['user_id'], X_test['user_id']]).unique())\n",
    "num_products = len(pd.concat([X_train['product_id'], X_val['product_id'], X_test['product_id']]).unique())\n",
    "EMBEDDING_SIZE = 50\n",
    "\n",
    "model = RecommenderNet(num_users, num_products, EMBEDDING_SIZE)\n",
    "model.compile(\n",
    "    loss=keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[[\"user_id\", \"product_id\"]].values\n",
    "y_train = y_train.values\n",
    "\n",
    "X_val = X_val[[\"user_id\", \"product_id\"]].values\n",
    "y_val = y_val.values\n",
    "\n",
    "X_test = X_test[[\"user_id\", \"product_id\"]].values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m9767/9767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 34ms/step - loss: 0.5827 - val_loss: 0.4979\n",
      "Epoch 2/5\n",
      "\u001b[1m9767/9767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 32ms/step - loss: 0.4699 - val_loss: 0.5168\n",
      "Epoch 3/5\n",
      "\u001b[1m9767/9767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 32ms/step - loss: 0.4705 - val_loss: 0.5179\n",
      "Epoch 4/5\n",
      "\u001b[1m9767/9767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 32ms/step - loss: 0.4787 - val_loss: 0.5170\n",
      "Epoch 5/5\n",
      "\u001b[1m9767/9767\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 32ms/step - loss: 0.4927 - val_loss: 0.5095\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    x=X_train,\n",
    "    y=y_train,\n",
    "    batch_size=64,\n",
    "    epochs=5,\n",
    "    verbose=1,\n",
    "    validation_data=(X_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performance of recommender net\n",
    "We see that as the embedding size increases, the accuracy decreases, this could be due to overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2962/2962\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 718us/step\n",
      "RMSE: 0.323795852662666\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "y_pred = model.predict(X_test).flatten()\n",
    "model_error = mean_squared_error(y_test, y_pred) ** 0.5\n",
    "print(f'RMSE: {model_error}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.32371858806334664\n"
     ]
    }
   ],
   "source": [
    "global_mean_rating = y_train.mean()\n",
    "\n",
    "def global_model(X):\n",
    "    # Predicts the mean score across all ratings, regardless of product or user\n",
    "    return np.ones(len(X)) * global_mean_rating\n",
    "\n",
    "y_pred = global_model(X_test)\n",
    "model_error = mean_squared_error(y_test, y_pred) ** 0.5\n",
    "print(f'RMSE: {model_error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = pd.DataFrame(X_train, columns=['user_id', 'product_id'])\n",
    "train_features['rating'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.3115740813686763\n"
     ]
    }
   ],
   "source": [
    "user_ratings = train_features.groupby(['user_id']).mean()['rating']\n",
    "\n",
    "def user_model(X):\n",
    "    # Predicts the mean score of previous user ratings, regardless of product\n",
    "    users = X[:,0]\n",
    "    return user_ratings[users]\n",
    "\n",
    "y_pred = user_model(X_test)\n",
    "model_error = mean_squared_error(y_test, y_pred) ** 0.5\n",
    "print(f'RMSE: {model_error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.31694089998797526\n"
     ]
    }
   ],
   "source": [
    "product_ratings = train_features.groupby(['product_id']).mean()['rating']\n",
    "\n",
    "# Handle cases where unknown products are shown\n",
    "product_ratings[-1] = global_mean_rating\n",
    "unique_products = train_features['product_id'].unique()\n",
    "\n",
    "def product_model(X):\n",
    "    # Predicts the mean score of previous product ratings, regardless of user\n",
    "    products = np.where(np.isin(X[:,1],unique_products), X[:,1], -1)\n",
    "    return product_ratings[products]\n",
    "\n",
    "y_pred = product_model(X_test)\n",
    "model_error = mean_squared_error(y_test, y_pred) ** 0.5\n",
    "print(f'RMSE: {model_error}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
